# üß† Framework de Engenharia de Prompt para Extra√ß√£o e Interpreta√ß√£o de Documentos PDF

## üéì Trabalho de Conclus√£o de Curso ‚Äì Sistemas de Informa√ß√£o  
**Tema:** Modelos de IA Generativa e a Pratica da Engenharia de Prompt
**Autor:** Carlos Henrique e Charles Dayan 
**Institui√ß√£o:** Universidade Federal de Sergipe (UFS)  

---

## üìò Objetivo do Projeto

O objetivo geral deste projeto √© **desenvolver um framework pr√°tico e acess√≠vel de engenharia de prompt** voltado para a **extra√ß√£o, interpreta√ß√£o e simplifica√ß√£o de conte√∫dos especializados presentes em documentos PDF**, utilizando **modelos de linguagem de grande escala (LLMs)**, com foco em **dom√≠nios t√©cnicos e normativos**.  

A proposta visa **tornar o acesso a informa√ß√µes complexas mais √°gil, acess√≠vel e confi√°vel**, permitindo que usu√°rios com diferentes n√≠veis de familiaridade compreendam conte√∫dos t√©cnicos ‚Äî como editais, normas e regulamentos ‚Äî por meio de **intera√ß√£o direta com modelos generativos**.

O framework permite comparar a performance de diferentes **modelos de IA generativa** ‚Äî tanto **locais (via Ollama)** quanto **em nuvem (via APIs oficiais)** ‚Äî oferecendo uma base pr√°tica para estudos e experimenta√ß√£o em **engenharia de prompt**.

---

## ‚öôÔ∏è Tecnologias Utilizadas

### üîπ Backend
- [FastAPI](https://fastapi.tiangolo.com/) ‚Äì Framework Python para cria√ß√£o de APIs r√°pidas e ass√≠ncronas  
- [Uvicorn](https://www.uvicorn.org/) ‚Äì Servidor ASGI de alto desempenho  
- [pdfplumber](https://github.com/jsvine/pdfplumber) ‚Äì Extra√ß√£o de texto de documentos PDF  
- [Ollama](https://ollama.ai/) ‚Äì Execu√ß√£o local de modelos LLM  
- [OpenAI API](https://platform.openai.com/docs/) ‚Äì Integra√ß√£o com ChatGPT  
- [Google Generative AI](https://aistudio.google.com/) ‚Äì Integra√ß√£o com Gemini  
- [DeepSeek API](https://www.deepseek.com/) ‚Äì Modelo de IA avan√ßado de c√≥digo aberto  

### üîπ Frontend
- HTML + Jinja2 (templating)  
- JavaScript (requisi√ß√µes ass√≠ncronas e interface din√¢mica)  
- CSS

---

## ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o

### 1Ô∏è‚É£ Pr√©-requisitos

Antes de rodar o projeto, garanta que voc√™ possui:

- **Python 3.10+**
- **pip** (gerenciador de pacotes)
- **[Ollama](https://ollama.ai/download)** instalado
- Modelos **DeepSeek** e **Llama** baixados via Ollama:
  ```bash
  ollama pull deepseek
  ollama pull llama3

‚ö†Ô∏è Caso o **Ollama** n√£o esteja instalado, o framework funcionar√° apenas com os modelos via API, como Gemini e GPT.


### 2Ô∏è‚É£ Clonar o reposit√≥rio

git clone https://github.com/charlescosta1/FRAMEWORK-TCC2.git

cd FRAMEWORK-TCC2

### 3Ô∏è‚É£ Instalar depend√™ncias

pip install -r requirements.txt

### 4Ô∏è‚É£ Configurar vari√°veis de ambiente

cp .env.example .env

## Exemplo de .env

- OPENAI_API_KEY=sua_chave_openai_aqui
- GEMINI_API_KEY=sua_chave_gemini_aqui

### 5Ô∏è‚É£ Executar o servidor
python -m uvicorn main:app --reload

Ap√≥s iniciar, acesse no navegador:
http://localhost:8000
